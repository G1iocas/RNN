{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, SimpleRNN, BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfccs(audio_files):\n",
    "    mfccs_features = []\n",
    "    \n",
    "    for file_path in audio_files:\n",
    "        try:\n",
    "            audio, _ = librosa.load(file_path, res_type='kaiser_fast', duration=30) \n",
    "            mfccs = librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=13)\n",
    "            mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "            mfccs_features.append(mfccs_processed)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while processing file:\", file_path)\n",
    "            print(e)\n",
    "            continue\n",
    "    \n",
    "    return mfccs_features\n",
    "\n",
    "def extract_spectrogram(audio_files):\n",
    "    spectrogram_features = []\n",
    "    \n",
    "    for file_path in audio_files:\n",
    "        try:\n",
    "            audio, _ = librosa.load(file_path, res_type='kaiser_fast', duration=30) \n",
    "            spectrogram = np.abs(librosa.stft(audio))\n",
    "            spectrogram_features.append(spectrogram)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while processing file:\", file_path)\n",
    "            continue\n",
    "    \n",
    "    return np.array(spectrogram_features)\n",
    "\n",
    "def extract_chroma(audio_files):\n",
    "    chroma_features = []\n",
    "    \n",
    "    for file_path in audio_files:\n",
    "        try:\n",
    "            audio, _ = librosa.load(file_path, res_type='kaiser_fast', duration=30) \n",
    "            chroma = librosa.feature.chroma_stft(y=audio, sr=22050)\n",
    "            chroma_features.append(chroma)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while processing file:\", file_path)\n",
    "            print(e)\n",
    "            continue\n",
    "    \n",
    "    return np.array(chroma_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, feature_type):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    try:\n",
    "        for folder in os.listdir(data_path):\n",
    "            genre_folder = os.path.join(data_path, folder)\n",
    "            if os.path.isdir(genre_folder):  # Check if it's a directory\n",
    "                print(\"Processing folder:\", genre_folder)\n",
    "                for file in os.listdir(genre_folder):\n",
    "                    file_path = os.path.join(genre_folder, file)\n",
    "                    if os.path.isfile(file_path):  # Check if it's a file\n",
    "                        print(\"Processing file:\", file_path)\n",
    "                        if feature_type == 'mfcc':\n",
    "                            feature = extract_mfccs([file_path])\n",
    "                            if feature:\n",
    "                                features.append(feature[0])\n",
    "                                labels.append(folder)\n",
    "                        elif feature_type == 'spectrogram':\n",
    "                            feature = extract_spectrogram([file_path])\n",
    "                            if feature:\n",
    "                                features.append(feature[0])\n",
    "                                labels.append(folder)\n",
    "                        elif feature_type == 'chroma':\n",
    "                            feature = extract_chroma([file_path])\n",
    "                            if feature:\n",
    "                                features.append(feature[0])\n",
    "                                labels.append(folder)\n",
    "                    else:\n",
    "                        print(\"Skipping non-file:\", file_path)\n",
    "            else:\n",
    "                print(\"Skipping non-directory:\", genre_folder)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during data loading:\", e)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: Data/genres_original\\blues\n",
      "Processing file: Data/genres_original\\blues\\blues.00000.wav\n",
      "Error occurred during data loading: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_path = 'Data/genres_original'  # Update with your dataset path\n",
    "#mfccs_features, mfccs_labels = load_data(data_path, feature_type='mfcc')\n",
    "spectrogram_features, spectrogram_labels = load_data(data_path, feature_type='spectrogram')\n",
    "#chroma_features, chroma_labels = load_data(data_path, feature_type='chroma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmfccs_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "mfccs_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m encoded_chroma_labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(chroma_labels)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert encoded labels into categorical labels\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m mfccs_labels_categorical \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_mfccs_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m spectrogram_labels_categorical \u001b[38;5;241m=\u001b[39m to_categorical(encoded_spectrogram_labels)\n\u001b[0;32m     10\u001b[0m chroma_labels_categorical \u001b[38;5;241m=\u001b[39m to_categorical(encoded_chroma_labels)\n",
      "File \u001b[1;32mc:\\Users\\JLCarunungan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:86\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(x, num_classes)\u001b[0m\n\u001b[0;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m num_classes:\n\u001b[1;32m---> 86\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     87\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     88\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n",
      "File \u001b[1;32mc:\\Users\\JLCarunungan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2698\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JLCarunungan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# Encode labels for each type of feature\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_mfccs_labels = label_encoder.fit_transform(mfccs_labels)\n",
    "encoded_spectrogram_labels = label_encoder.fit_transform(spectrogram_labels)\n",
    "encoded_chroma_labels = label_encoder.fit_transform(chroma_labels)\n",
    "\n",
    "# Convert encoded labels into categorical labels\n",
    "mfccs_labels_categorical = to_categorical(encoded_mfccs_labels)\n",
    "spectrogram_labels_categorical = to_categorical(encoded_spectrogram_labels)\n",
    "chroma_labels_categorical = to_categorical(encoded_chroma_labels)\n",
    "\n",
    "# Convert lists of features into NumPy arrays\n",
    "mfccs_features_array = np.array(mfccs_features)\n",
    "spectrogram_features_array = np.array(spectrogram_features)\n",
    "chroma_features_array = np.array(chroma_features)\n",
    "\n",
    "# Print shapes of features and labels with feature types indicated\n",
    "print(\"MFCCs features shape:\", mfccs_features_array.shape, \"(MFCCs)\")\n",
    "print(\"Spectrogram features shape:\", spectrogram_features_array.shape, \"(Spectrogram)\")\n",
    "print(\"Chroma features shape:\", chroma_features_array.shape, \"(Chroma)\")\n",
    "print(\"MFCCs Labels shape:\", mfccs_labels_categorical.shape)\n",
    "print(\"Spectrogram Labels shape:\", spectrogram_labels_categorical.shape)\n",
    "print(\"Chroma Labels shape:\", chroma_labels_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train_mfccs, X_test_mfccs, y_train_mfccs, y_test_mfccs = train_test_split(mfccs_features_array, mfccs_labels_categorical, test_size=0.2, random_state=42)\n",
    "X_train_spectrogram, X_test_spectrogram, y_train_spectrogram, y_test_spectrogram = train_test_split(spectrogram_features_array, spectrogram_labels_categorical, test_size=0.2, random_state=42)\n",
    "X_train_chroma, X_test_chroma, y_train_chroma, y_test_chroma = train_test_split(chroma_features_array, chroma_labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the split sets\n",
    "print(\"MFCCs features - Train shape:\", X_train_mfccs.shape, \"Test shape:\", X_test_mfccs.shape)\n",
    "print(\"Spectrogram features - Train shape:\", X_train_spectrogram.shape, \"Test shape:\", X_test_spectrogram.shape)\n",
    "print(\"Chroma features - Train shape:\", X_train_chroma.shape, \"Test shape:\", X_test_chroma.shape)\n",
    "print(\"MFCCs Labels shape - Train:\", y_train_mfccs.shape, \"Test:\", y_test_mfccs.shape)\n",
    "print(\"Spectrogram Labels shape - Train:\", y_train_spectrogram.shape, \"Test:\", y_test_spectrogram.shape)\n",
    "print(\"Chroma Labels shape - Train:\", y_train_chroma.shape, \"Test:\", y_test_chroma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data to have the appropriate shape for RNN for each set of features\n",
    "X_train_mfccs_reshaped = X_train_mfccs.reshape(X_train_mfccs.shape[0], X_train_mfccs.shape[1], 1)\n",
    "X_test_mfccs_reshaped = X_test_mfccs.reshape(X_test_mfccs.shape[0], X_test_mfccs.shape[1], 1)\n",
    "\n",
    "X_train_spectrogram_reshaped = X_train_spectrogram.reshape(X_train_spectrogram.shape[0], X_train_spectrogram.shape[1], 1)\n",
    "X_test_spectrogram_reshaped = X_test_spectrogram.reshape(X_test_spectrogram.shape[0], X_test_spectrogram.shape[1], 1)\n",
    "\n",
    "X_train_chroma_reshaped = X_train_chroma.reshape(X_train_chroma.shape[0], X_train_chroma.shape[1], 1)\n",
    "X_test_chroma_reshaped = X_test_chroma.reshape(X_test_chroma.shape[0], X_test_chroma.shape[1], 1)\n",
    "\n",
    "# Print shapes of the reshaped sets\n",
    "print(\"MFCCs features - Train shape (reshaped):\", X_train_mfccs_reshaped.shape, \"Test shape (reshaped):\", X_test_mfccs_reshaped.shape)\n",
    "print(\"Spectrogram features - Train shape (reshaped):\", X_train_spectrogram_reshaped.shape, \"Test shape (reshaped):\", X_test_spectrogram_reshaped.shape)\n",
    "print(\"Chroma features - Train shape (reshaped):\", X_train_chroma_reshaped.shape, \"Test shape (reshaped):\", X_test_chroma_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the model\n",
    "def create_model(input_shape, learning_rate=0.001, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))  # Add dropout layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SimpleRNN(units=64, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))  # Add dropout layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SimpleRNN(units=32))\n",
    "    model.add(Dropout(dropout_rate))  # Add dropout layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=len(label_encoder.classes_), activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize variables to store best score and parameters for each feature set\n",
    "best_scores = {'mfccs': 0, 'spectrogram': 0, 'chroma': 0}\n",
    "best_params = {'mfccs': {}, 'spectrogram': {}, 'chroma': {}}\n",
    "\n",
    "# Define lists of hyperparameters to search over\n",
    "learning_rates = [0.001, 0.0015, 0.002]\n",
    "dropout_rates = [0.1, 0.2]\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "epochs_list = [30, 40, 50, 60]\n",
    "\n",
    "# Iterate over all combinations of hyperparameters for each feature set\n",
    "for feature_type, X_train, X_test in [('mfccs', X_train_mfccs_reshaped, X_test_mfccs_reshaped),\n",
    "                                      ('spectrogram', X_train_spectrogram_reshaped, X_test_spectrogram_reshaped),\n",
    "                                      ('chroma', X_train_chroma_reshaped, X_test_chroma_reshaped)]:\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                for epochs in epochs_list:\n",
    "                    # Create model with current hyperparameters\n",
    "                    model = create_model(input_shape=X_train.shape[1:], learning_rate=lr, dropout_rate=dropout_rate)\n",
    "                    \n",
    "                    # Train the model\n",
    "                    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "                    \n",
    "                    # Evaluate the model on validation data\n",
    "                    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "                    \n",
    "                    # Store the accuracy and parameters if it's the best for the current feature set\n",
    "                    if accuracy > best_scores[feature_type]:\n",
    "                        best_scores[feature_type] = accuracy\n",
    "                        best_params[feature_type] = {'learning_rate': lr, 'dropout_rate': dropout_rate, 'batch_size': batch_size, 'epochs': epochs}\n",
    "                    \n",
    "                    # Print accuracy and parameters for each iteration\n",
    "                    params = {'learning_rate': lr, 'dropout_rate': dropout_rate, 'batch_size': batch_size, 'epochs': epochs}\n",
    "                    print(f\"Feature Type: {feature_type}, Accuracy: {accuracy}, Parameters: {params}\")\n",
    "\n",
    "# Print the best scores and parameters for each feature set\n",
    "for feature_type in best_scores:\n",
    "    print(f\"Best Mean Test Accuracy ({feature_type}):\", best_scores[feature_type])\n",
    "    print(f\"Best Parameters ({feature_type}):\", best_params[feature_type])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
